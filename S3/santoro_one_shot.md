##One-shot Learning - Santoro

En primer lugar es interesante el _approach_ de **one-shot**. Se menciona que una de las limitaciones de los modelos tradicionales de deep learning es que si bien tienen resultados notables, requieren entrenamientos extensivos y muy adaptados al dominio de los problemas, de modo que al enfrentarse a dominios similares pero no del todo, se debe realizar un nuevo entrenamiento para adaptar el modelo al problema. En _one-shot learning_ la idea es, con poco entrenamiento poder ser flexible a los cambios del dominio, imitando una característica atribuida a los humanos, la de poder realizar aprendizajes y nuevas inferencias con poca información nueva.

A diferencia del paper de Weston, et al. en este se intenta abordar el problema no solo de acceder a una memoria de manera eficiente y escalable, sino que también de adecuar el problema al desafio de _meta learning_ o como lo describen _learning to learn_. Esto pretende ayudar a extender el rango de problemas en el que deep learning se puede aplicar eficazmente por medio de aprender rapidamente de información previamente no vista, utilizando memorias externas. Para esto, en la tarea de _meta learning_ se busca encontrar los parámetros adecuados para minimizar el costo de aprendizaje sobre una distrubución de sets de datos.

Es interesante la distinción que hacen sobre la forma de abordar la memoria que se usa en modelos como NTM, ya que ahí se ve desde el punto de vista del contenido y de la ubicación, sin embargo se argumenta que para este caso lo más importante es el contenido y en específico sobre la información que es más reciente, actualizando por medio de LRUA, de modo de actualizar con información más nueva y posiblemente más relevante para la tarea de aprender a aprender.

Para probar su modelo, se basaron en el dataset Omniglot que corresponde a una collección de símbolos de distintos lenguajes con 1600 clases con pocos ejemplos por clase, de modo de ser útil para _one-shot_. El experimento consistió en mostrar a los modelos instancias de clases elegidas al azar y luego informar al modelo del resultado real, solo con 10 instancias. Esto muestra que se requiere muy pocas instancias, y como se ve en los resultados, al décimo ejemplo el desempeño es notable, superior al de humanos y a LST y FeedForward. La diferencia se acrecienta cuando la cantidad de clases crece, ya que por ejemplo para humanos es imposible retener tantas clases.

Luego se prueba el modelo MANN para regresión y también se ve que mejora los resultados respecto a un proceso gaussiano.

Sin embargo, hay dos puntos que me parece podrían haber sido abordados de mejor manera para propiciar un mayor entendimiento, primero la migración del método de escritura de memoria de tipo content-based y location-based a solo content-based solo se argumenta en que la primera no es óptima para tareas de secuencias independientes, sin embargo no se explica por qué. Segundo, que el set de datos en el que se hacen los testeos parece ser a mi juicio un poco sesgado ya que es bastante estructurado y creo que el objetivo del paper es mucho más ambicioso que lo que se consigue probar con este dataset y tarea.

Por último señalar que tal como se menciona en el paper, uno de los grandes aportes de este trabajo es el hecho de que las tareas estudiadas no se pueden realizar solo bajo el poder de la memorización pura, sino que se requiere poder acceder y almacenar la información de manera flexible y eficiente, no solo precisa. Se ve un esfuerzo por imitar el comportamiento humano en como se mezcla memoria flexible y la evaluación de nuevos escenarios, incluso superando en los resultados a los mismos humanos.

Raimundo Herrera Sufán