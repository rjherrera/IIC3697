##Summarization GetToThePoint

En este paper, al igual que en el otro leído, se menciona bastante los esfuerzos por evitar la repetición de pasajes, y el nuevo desafio que se presenta de no solo seleccionar pasajes relevantes de los textos, sino que hacer _abstracción_ de los mismos y generar frases adecuadas.

Cuando se habla del método _pointer-generator_, creo que es importante destacar la mención a las _OOV (out of vocabulary) words_, ya que el hecho de que se generen palabras fuera del vocabulario entregado repercute en que se pueda entrenar el modelo con cantidades de datos significativamente menores, lo que se menciona en el paper y a mi parecer es un punto muy rescatable. Esto combinado con el _coverage_ del que se hablará más adelante, no complejizan significativamente el modelo en términos de parámetros pero si logran reducir la cantidad de datos necesarios, lo que afecta dramáticamente los tiempos de entrenamiento.

La inclusión de una métrica de _coverage_ creo que es fundamental para los resultados del paper y creo que está muy bien abordada. Esto porque se aborda la noción de repetición como un problema a evitar pero se tiene en cuenta la noción de que tener un _coverage_ uniforme, esto es cubrir uniformemente todas las palabras del texto no es el resultado deseado, a diferencia de otros modelos. Me parece interesante que más adelante se aborde en este paper, a diferencia del anterior, la importancia del hiperparámetro _gamma_, de modo que se incluye un análisis, a mi parecer necesario, de que ciertos valores no influyen positivamente en el resultado mientras que otros sí. Por otro lado, se muestra que efectivamente el problema de la repetición es eficazmente resuelto por la inclusión de las técnicas de _coverage_ ya que a pesar del poco tiempo adicional de entrenamiento que toma, se elimina casi por completo el problema.

Es importante destacar el esfuerzo del paper por explicar los rendimientos de los modelos en cuanto a ROGUE. En un primer vistazo a los resultados de sus modelos me parecía que los resultados eran evidentemente superiores a los de otros modelos ahí mostrados, sin embargo, las puntuaciones muy similares. El hecho de basar gran parte de los resultados en métricas no necesariamente adecuadas para el problema me parece un problema real y quizás no abordado por el paper anterior. Esfuerzos en mejorar los resultados en cuanto a la métrica pueden ser inútiles si se termina de cierto modo _overfitteando_ (o algún término análogo a ese para el concepto de métricas) para esa métrica en particular. Quizás se requieran nuevas investigaciones y generación de Datasets y métricas más adecuadas para el problema en su formato _abstractive_, como lo que se vio en la sesión de lectura pasada, donde se formuló todo un dataset y medidas para el problema de VQA en particular. De hecho, creo que evaluar respecto a métricas como ROGUE o METEOR puede ser contraproducente para medidas como el _coverage_ ya que si bien el entrenamiento penaliza la repetición, el score del modelo quizás no, haciendo infructuosos los esfuerzos.

Finalmente añadir que mirando los ejemplos adjuntos al final, se puede ver a mi parecer consecuencias de lo mencionado anteriormente, ya que el mejor resultado pareciera evidentemente ser el del modelo final de _pointer-generator_ con _coverage_, sin embargo, las puntuaciones generales de dicho modelo no son tanto superiores, pero es claro que debe haber una forma objetiva de medirlo.

Raimundo Herrera Sufán